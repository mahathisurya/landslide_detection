{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOzftwf9+iZAUaO8MGKysaw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AcZMHuYz1COk","executionInfo":{"status":"ok","timestamp":1745803197359,"user_tz":-330,"elapsed":3836,"user":{"displayName":"mahathi s","userId":"04606415790539913915"}},"outputId":"0ac453c6-ea23-4501-8421-72c56fcd09c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","source":["\n","!pip install segmentation-models==1.0.1\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lqSHUI-81GKl","executionInfo":{"status":"ok","timestamp":1745803205562,"user_tz":-330,"elapsed":6674,"user":{"displayName":"mahathi s","userId":"04606415790539913915"}},"outputId":"3029573f-3d9f-42b5-f526-52100fe40cf5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: segmentation-models==1.0.1 in /usr/local/lib/python3.11/dist-packages (1.0.1)\n","Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from segmentation-models==1.0.1) (1.0.8)\n","Requirement already satisfied: image-classifiers==1.0.0 in /usr/local/lib/python3.11/dist-packages (from segmentation-models==1.0.1) (1.0.0)\n","Requirement already satisfied: efficientnet==1.0.0 in /usr/local/lib/python3.11/dist-packages (from segmentation-models==1.0.1) (1.0.0)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from efficientnet==1.0.0->segmentation-models==1.0.1) (0.25.2)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (1.23.5)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (3.13.0)\n","Collecting numpy>=1.9.1 (from keras-applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1)\n","  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.14.1)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (3.4.2)\n","Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (11.1.0)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.37.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2025.3.30)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (24.2)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (0.4)\n","Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.23.5\n","    Uninstalling numpy-1.23.5:\n","      Successfully uninstalled numpy-1.23.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 2.2.5 which is incompatible.\n","tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\n","flax 0.10.5 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n","tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n","orbax-checkpoint 0.11.12 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\n","tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n","ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-2.2.5\n"]}]},{"cell_type":"code","source":["!pip uninstall -y numpy protobuf tensorflow keras\n","!pip cache purge\n","!pip install numpy==1.23.5 protobuf==3.20.3 tensorflow==2.12.0 keras==2.12.0\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"SuBO5otw1PbD","executionInfo":{"status":"ok","timestamp":1745803265958,"user_tz":-330,"elapsed":57302,"user":{"displayName":"mahathi s","userId":"04606415790539913915"}},"outputId":"b4cf959d-ed06-4ffa-92dd-d2d55d14515f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: numpy 2.2.5\n","Uninstalling numpy-2.2.5:\n","  Successfully uninstalled numpy-2.2.5\n","Found existing installation: protobuf 3.20.3\n","Uninstalling protobuf-3.20.3:\n","  Successfully uninstalled protobuf-3.20.3\n","Found existing installation: tensorflow 2.12.0\n","Uninstalling tensorflow-2.12.0:\n","  Successfully uninstalled tensorflow-2.12.0\n","Found existing installation: keras 2.12.0\n","Uninstalling keras-2.12.0:\n","  Successfully uninstalled keras-2.12.0\n","Files removed: 114\n","Collecting numpy==1.23.5\n","  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n","Collecting protobuf==3.20.3\n","  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n","Collecting tensorflow==2.12.0\n","  Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Collecting keras==2.12.0\n","  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.71.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.13.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.30)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (24.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.3)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.0.1)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.13.2)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.1)\n","Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.30)\n","Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n","Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.14.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.8)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2025.1.31)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n","Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (586.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.0/586.0 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: protobuf, numpy, keras, tensorflow\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n","pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n","imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n","flax 0.10.5 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n","scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n","chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n","tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n","treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n","bigframes 2.1.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n","orbax-checkpoint 0.11.12 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\n","xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n","albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n","tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n","blosc2 3.3.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n","ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n","grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n","albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n","tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-2.12.0 numpy-1.23.5 protobuf-3.20.3 tensorflow-2.12.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google","numpy"]},"id":"57e1d159bc9f462c87462e14121f251a"}},"metadata":{}}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import backend as K\n","\n","def f1_score(y_true, y_pred):\n","    y_pred = K.round(y_pred)\n","    tp = K.sum(K.cast(y_true * y_pred, 'float32'))\n","    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float32'))\n","    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float32'))\n","\n","    precision = tp / (tp + fp + K.epsilon())\n","    recall = tp / (tp + fn + K.epsilon())\n","\n","    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n","    return f1"],"metadata":{"id":"2wZXWlOy13oy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","\n","custom_objects = {\n","    'f1-score': f1_score,\n","    'precision': tf.keras.metrics.Precision,\n","    'recall': tf.keras.metrics.Recall\n","}\n","\n","model = load_model('/content/drive/MyDrive/dataset/model_copy.h5', custom_objects=custom_objects)"],"metadata":{"id":"U6KzZpco14Yo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n"],"metadata":{"id":"uXC0G83l3LNM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","class UNet(nn.Module):\n","    def __init__(self):\n","        super(UNet, self).__init__()\n","        def CBR(in_channels, out_channels):\n","            return nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, 3, padding=1),\n","                nn.ReLU(inplace=True),\n","                nn.Conv2d(out_channels, out_channels, 3, padding=1),\n","                nn.ReLU(inplace=True)\n","            )\n","\n","        self.enc1 = CBR(3, 32)\n","        self.enc2 = CBR(32, 64)\n","        self.enc3 = CBR(64, 128)\n","        self.pool = nn.MaxPool2d(2)\n","        self.upconv2 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n","        self.dec2 = CBR(128, 64)\n","        self.upconv1 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n","        self.dec1 = CBR(64, 32)\n","        self.final = nn.Conv2d(32, 1, 1)\n","\n","    def forward(self, x):\n","        enc1 = self.enc1(x)\n","        enc2 = self.enc2(self.pool(enc1))\n","        enc3 = self.enc3(self.pool(enc2))\n","        dec2 = self.upconv2(enc3)\n","        dec2 = torch.cat((dec2, enc2), dim=1)\n","        dec2 = self.dec2(dec2)\n","        dec1 = self.upconv1(dec2)\n","        dec1 = torch.cat((dec1, enc1), dim=1)\n","        dec1 = self.dec1(dec1)\n","        return torch.sigmoid(self.final(dec1))\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = UNet().to(device)\n","model.load_state_dict(torch.load('/content/drive/MyDrive/unet_model.pth', map_location=device))\n","model.eval()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4EzM4hf424p8","executionInfo":{"status":"ok","timestamp":1745803350167,"user_tz":-330,"elapsed":650,"user":{"displayName":"mahathi s","userId":"04606415790539913915"}},"outputId":"83a4f876-dff1-493c-ad8e-4b49db74f4e1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["UNet(\n","  (enc1): Sequential(\n","    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","  )\n","  (enc2): Sequential(\n","    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","  )\n","  (enc3): Sequential(\n","    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","  )\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (upconv2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n","  (dec2): Sequential(\n","    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","  )\n","  (upconv1): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n","  (dec1): Sequential(\n","    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","  )\n","  (final): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["!pip install gradio h5py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k8TWW21K3kGu","executionInfo":{"status":"ok","timestamp":1745803579320,"user_tz":-330,"elapsed":4043,"user":{"displayName":"mahathi s","userId":"04606415790539913915"}},"outputId":"0230bdc9-758c-461f-9a11-16a8c8a115bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.27.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (3.13.0)\n","Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n","Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n","Requirement already satisfied: gradio-client==1.9.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.9.0)\n","Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n","Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n","Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.23.5)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n","Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n","Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n","Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.7)\n","Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n","Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n","Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (2025.3.2)\n","Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (15.0.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.8)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import gradio as gr\n","import numpy as np\n","import tensorflow as tf\n","import h5py\n","from PIL import Image\n","from torchvision import transforms as T\n","\n","#FIRST MODEL\n","class UNet(nn.Module):\n","    def __init__(self):\n","        super(UNet, self).__init__()\n","        def CBR(in_channels, out_channels):\n","            return nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, 3, padding=1),\n","                nn.ReLU(inplace=True),\n","                nn.Conv2d(out_channels, out_channels, 3, padding=1),\n","                nn.ReLU(inplace=True)\n","            )\n","\n","        self.enc1 = CBR(3, 32)\n","        self.enc2 = CBR(32, 64)\n","        self.enc3 = CBR(64, 128)\n","\n","        self.pool = nn.MaxPool2d(2)\n","\n","        self.upconv2 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n","        self.dec2 = CBR(128, 64)\n","        self.upconv1 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n","        self.dec1 = CBR(64, 32)\n","\n","        self.final = nn.Conv2d(32, 1, 1)\n","\n","    def forward(self, x):\n","        enc1 = self.enc1(x)\n","        enc2 = self.enc2(self.pool(enc1))\n","        enc3 = self.enc3(self.pool(enc2))\n","\n","        dec2 = self.upconv2(enc3)\n","        dec2 = torch.cat((dec2, enc2), dim=1)\n","        dec2 = self.dec2(dec2)\n","\n","        dec1 = self.upconv1(dec2)\n","        dec1 = torch.cat((dec1, enc1), dim=1)\n","        dec1 = self.dec1(dec1)\n","\n","        return torch.sigmoid(self.final(dec1))\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","pytorch_model = UNet()\n","pytorch_model.load_state_dict(torch.load(\"/content/drive/MyDrive/unet_model.pth\", map_location=device))\n","pytorch_model.to(device)\n","pytorch_model.eval()\n","\n","#Preprocessing\n","def preprocess_image(img):\n","    transform = T.Compose([\n","        T.Resize((256, 256)),\n","        T.ToTensor()\n","    ])\n","    return transform(img).unsqueeze(0)\n","\n","def predict(file):\n","    img = Image.open(file).convert('RGB')\n","    input_tensor = preprocess_image(img)\n","\n","    with torch.no_grad():\n","        output = pytorch_model(input_tensor)\n","        output = output.squeeze().cpu().numpy()\n","\n","\n","    threshold_value = 0.05\n","    binary_output = (output > threshold_value).astype(np.uint8) * 255\n","\n","    output_img = Image.fromarray(binary_output)\n","\n","    return output_img\n","\n","#SECOND MODEL\n","custom_objects = {\n","    'f1-score': lambda y_true, y_pred: 0,\n","    'precision': tf.keras.metrics.Precision,\n","    'recall': tf.keras.metrics.Recall\n","}\n","tf_model = tf.keras.models.load_model('/content/drive/MyDrive/dataset/model_copy.h5', custom_objects=custom_objects)\n","\n","def predict_satellite_image(h5_file):\n","    with h5py.File(h5_file.name, 'r') as f:\n","        data = np.array(f['img'])\n","\n","    rgb = np.stack([\n","        data[:, :, 3],\n","        data[:, :, 2],\n","        data[:, :, 1]\n","    ], axis=-1)\n","\n","    rgb_norm = (rgb / np.max(rgb) * 255).astype(np.uint8)\n","    input_rgb_image = Image.fromarray(rgb_norm)\n","\n","    mid_rgb = data[:, :, 1:4].max() / 2.0\n","    mid_slope = data[:, :, 12].max() / 2.0\n","    mid_elevation = data[:, :, 13].max() / 2.0\n","\n","    red = data[:, :, 3]\n","    nir = data[:, :, 7]\n","    ndvi = np.divide(nir - red, nir + red + 1e-7)\n","\n","    processed = np.zeros((128, 128, 6))\n","    processed[:, :, 0] = 1 - red / mid_rgb\n","    processed[:, :, 1] = 1 - data[:, :, 2] / mid_rgb\n","    processed[:, :, 2] = 1 - data[:, :, 1] / mid_rgb\n","    processed[:, :, 3] = ndvi\n","    processed[:, :, 4] = 1 - data[:, :, 12] / mid_slope\n","    processed[:, :, 5] = 1 - data[:, :, 13] / mid_elevation\n","\n","    input_tensor = np.expand_dims(processed, axis=0)\n","    predicted_mask = tf_model.predict(input_tensor)[0]\n","\n","    mask_img = Image.fromarray((predicted_mask.squeeze() * 255).astype(np.uint8))\n","\n","    return input_rgb_image, mask_img\n","\n","\n","\n","def master_predict(choice, input_file):\n","    if choice == \"Regular Image\":\n","        return predict(input_file), None\n","    else:\n","        return predict_satellite_image(input_file)\n","\n","#Gradio\n","interface = gr.Interface(\n","    fn=master_predict,\n","    inputs=[\n","        gr.Radio([\"Regular Image\", \"Satellite Image\"], label=\"Select Input Type\"),\n","        gr.File(label=\"Upload your file\")\n","    ],\n","    outputs=[\n","        gr.Image(type=\"pil\", label=\"Result 1\"),\n","        gr.Image(type=\"pil\", label=\"Result 2 (Only for Satellite)\")\n","    ],\n","    title=\"Landslide Mask Prediction\",\n","    description=\"Choose between regular image or satellite image (.h5) for segmentation.\"\n",")\n","\n","interface.launch(debug=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":680},"id":"JNy2QpETFUIR","executionInfo":{"status":"ok","timestamp":1745803876985,"user_tz":-330,"elapsed":288189,"user":{"displayName":"mahathi s","userId":"04606415790539913915"}},"outputId":"2aa155dd-a422-4a87-9250-4498b99fb36b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://8681766d8c34ad89c7.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://8681766d8c34ad89c7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Keyboard interruption in main thread... closing server.\n","Killing tunnel 127.0.0.1:7860 <> https://8681766d8c34ad89c7.gradio.live\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":10}]}]}